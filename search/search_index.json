{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"introduction","text":"<p>Digital Wallet backed is a USSD based wallet that enables users to receive money to their digital wallet from mobile money wallet and transact to various sources i.e make bank payments, mobile money payments, p2p payments to another digital wallet, Till number and paybill payments.</p> <p>This backend is divided into 3 services</p> <ul> <li> <p>Core <code>[/src]</code>- Flask server acting as the core that glues all services and connects to our main postgres database. It Exposes all APIs needed to perform any manupulation of the digital wallet</p> </li> <li> <p>SMS service <code>[/sms]</code> - A python lambda that sends SMS via Africastaking API</p> </li> <li> <p>USSD service <code>[/ussd]</code> - A JS lambda that handles USSD webhooks from Africa's talking USSD service to serve the relevant menu in the USSD flow. Uses APIs from the Core to access and manipulate the digital wallet.</p> </li> </ul> <p></p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#core-requirements","title":"Core Requirements:","text":"<p>Install the following base requirements.</p> <ol> <li>Posgresql</li> <li>NodeJS</li> <li>Terraform</li> <li>Python 3.9</li> <li>Virtualenv</li> <li>Make</li> <li>Docker</li> </ol>"},{"location":"installation/#posgresql","title":"Posgresql","text":"UbuntuOSX <p>Update apt</p> <pre><code>sudo apt update\n</code></pre> <p>Then, install the Postgres package along with a -contrib package that adds some additional utilities and functionality</p> <pre><code>sudo apt install postgresql postgresql-contrib\n</code></pre> <p>Press Y when prompted to confirm installation. If you are prompted to restart any services, press ENTER to accept the defaults and continue.</p> <p>Before you install anything with Homebrew, you should always make sure it\u2019s up to date and that it\u2019s healthy:</p> <pre><code>brew update \\\n&amp;&amp; brew doctor\n</code></pre> <p>install postgress</p> <pre><code>brew install postgresql@14\n</code></pre> <p>start the postgres service</p> <pre><code>brew services start postgresql@14\n</code></pre> <p>Wait a few seconds, then confirm that it\u2019s running</p> <pre><code>brew services list\n</code></pre>"},{"location":"installation/#nodejs","title":"NodeJS","text":"UbuntuOSX <p>Update apt</p> <pre><code>sudo apt update\n</code></pre> <p>Then install Node.js</p> <pre><code>sudo apt install nodejs\n</code></pre> <p>Check that the install was successful by querying node for its version number</p> <pre><code>node -v\n</code></pre> <p>Before you install anything with Homebrew, you should always make sure it\u2019s up to date and that it\u2019s healthy:</p> <pre><code>brew update \\\n&amp;&amp; brew doctor\n</code></pre> <p>install nodejs</p> <pre><code>brew install node\n</code></pre> <p>Check that the install was successful by querying node for its version number</p> <pre><code>node -v\n</code></pre>"},{"location":"installation/#terraform","title":"Terraform","text":"UbuntuOSX <p>Ensure that your system is up to date and you have installed the gnupg, software-properties-common, and curl packages installed. You will use these packages to verify HashiCorp's GPG signature and install HashiCorp's Debian package repository.</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y gnupg software-properties-common\n</code></pre> <p>Install the HashiCorp GPG key.</p> <pre><code>wget -O- https://apt.releases.hashicorp.com/gpg | \\\ngpg --dearmor | \\\nsudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg &gt; /dev/null\n</code></pre> <p>Verify the key's fingerprint.</p> <pre><code>gpg --no-default-keyring \\\n--keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg \\\n--fingerprint\n</code></pre> <p>Add the official HashiCorp repository to your system. The lsb_release -cs command finds the distribution release codename for your current system, such as buster, groovy, or sid.</p> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\nhttps://apt.releases.hashicorp.com $(lsb_release -cs) main\" | \\\nsudo tee /etc/apt/sources.list.d/hashicorp.list\n</code></pre> <p>Download the package information from HashiCorp.</p> <pre><code>sudo apt update\n</code></pre> <p>Install Terraform from the new repository.</p> <pre><code>sudo apt-get install terraform\n</code></pre> <p>update Homebrew.</p> <pre><code>brew update\n</code></pre> <p>Install the HashiCorp tap, a repository of all our Homebrew packages.</p> <pre><code>brew tap hashicorp/tap\n</code></pre> <p>Now, install Terraform with hashicorp/tap/terraform.</p> <pre><code>brew install hashicorp/tap/terraform\n</code></pre> <p>Verify the installation</p> <pre><code>terraform -help\n</code></pre>"},{"location":"installation/#python-39","title":"Python 3.9","text":"UbuntuOSX <p>Update apt.</p> <pre><code>sudo apt update\n</code></pre> <p>Add the deadsnakes PPA repository to the system</p> <pre><code>sudo add-apt-repository ppa:deadsnakes/ppa\n</code></pre> <p>install python3.9</p> <pre><code>sudo apt install python3.9 -y\n</code></pre> <p>update Homebrew.</p> <p><pre><code>brew update\n</code></pre> Now, install python3.9.</p> <pre><code>brew install python@3.9\n</code></pre> <p>validate python version</p> <pre><code>python3.9 --version\n</code></pre>"},{"location":"installation/#virtualenv","title":"Virtualenv","text":"UbuntuOSX <p>Update apt.</p> <pre><code>sudo apt update\n</code></pre> <p>Add the deadsnakes PPA repository to the system</p> <pre><code>sudo add-apt-repository ppa:deadsnakes/ppa\n</code></pre> <p>install python3.9-venv</p> <pre><code>sudo apt install  -y python3.9-venv python3.9-dev\n</code></pre> <p>update Homebrew.</p> <p><pre><code>brew update\n</code></pre> Now, install virtualenv</p> <pre><code>brew install virtualenv\n</code></pre>"},{"location":"installation/#make","title":"Make","text":"UbuntuOSX <p>Update apt.</p> <pre><code>sudo apt update\n</code></pre> <p>install make</p> <pre><code>sudo apt install make\n</code></pre> <p>update Homebrew.</p> <p><pre><code>brew update\n</code></pre> Now, install Make</p> <pre><code>brew install make\n</code></pre>"},{"location":"installation/#docker","title":"Docker","text":"UbuntuOSX <p>Follow instructions in https://docs.docker.com/engine/install/ubuntu/</p> <p>Follow instructions in https://docs.docker.com/desktop/install/mac-install/</p>"},{"location":"installation/#dev-environment-setup","title":"Dev Environment Setup","text":"UbuntuOSX <p>create a virtualenv  <pre><code>python3.9 -m venv dw-env\n</code></pre> activate virtualenv  by running the following <pre><code>source dw-env/bin/activate\n</code></pre></p> <p>configure the new env with pip</p> <p><pre><code>python -m pip install --upgrade pip==21.0.1\npip install -q setuptools-rust wheel\n</code></pre> Clone the repo <pre><code>git clone git@github.com:Exodus-Mobility/dw-backend.git\n</code></pre> Navigate to the core backend folder <pre><code>cd dw-backend/src\n</code></pre> Install the requirements <pre><code>pip install  -e .\n</code></pre> Create the  the test database from the command line by running the script: <pre><code>createdb sandbox_test\n</code></pre></p> <p>Set up node and install ussd dependencies</p> <pre><code>cd ussd &amp;&amp; yarn\n</code></pre> <p>To run core backend locally, using mocked aws (<code>localstack</code>): 1. Export your Tanda test keys <pre><code>export TANDA_CLIENT_ID=&lt;the client id&gt;\nexport TANDA_CLIENT_SECRET=&lt;the client secret&gt;\nexport TANDA_ORG_ID=&lt;the org id&gt;\n</code></pre></p> <ol> <li> <p>start the services using make <pre><code>make\n</code></pre> This will create docker containers with core service and other AWS components provisioned in the <code>Makefile</code> and make it available locally.</p> </li> <li> <p>reach the backend service on <code>http://localhost:4080</code>: admin dashboad - <code>/admin</code>  credentials(<code>username=admin</code>, <code>password=@SuperStrongPassword</code>) backend API - <code>/api/...</code> IPN hooks   - <code>/hooks/...</code></p> </li> </ol> <p>To stop the running services: <pre><code>make stop-core-backend\n</code></pre></p> <p>create a virtualenv  <pre><code>python -m virtualenv --python=python3.9 dw-env\n</code></pre> activate virtualenv  by running the following <pre><code>source dw-env/bin/activate\n</code></pre></p> <p>configure the new env with pip</p> <p><pre><code>python -m pip install --upgrade pip==21.0.1\npip install -q setuptools-rust wheel\n</code></pre> Clone the repo <pre><code>git clone git@github.com:Exodus-Mobility/dw-backend.git\n</code></pre> Navigate to the core backend folder <pre><code>cd dw-backend/src\n</code></pre> Install the requirements <pre><code>pip install  -e .\n</code></pre> Create the  the test database from the command line by running the script: <pre><code>createdb sandbox_test\n</code></pre></p> <p>Set up node and install ussd dependencies</p> <pre><code>cd ussd &amp;&amp; yarn\n</code></pre> <p>To run core backend locally, using mocked aws (<code>localstack</code>): 1. Export your Tanda test keys <pre><code>export TANDA_CLIENT_ID=&lt;the client id&gt;\nexport TANDA_CLIENT_SECRET=&lt;the client secret&gt;\nexport TANDA_ORG_ID=&lt;the org id&gt;\n</code></pre></p> <ol> <li> <p>start the services using make <pre><code>make\n</code></pre> This will create docker containers with core service and other AWS components provisioned in the <code>Makefile</code> and make it available locally.</p> </li> <li> <p>reach the backend service on <code>http://localhost:4080</code>: admin dashboad - <code>/admin</code>  credentials(<code>username=admin</code>, <code>password=@SuperStrongPassword</code>) backend API - <code>/api/...</code> IPN hooks   - <code>/hooks/...</code></p> </li> </ol> <p>To stop the running services: <pre><code>make stop-core-backend\n</code></pre></p>"},{"location":"sms/","title":"SMS Service","text":""},{"location":"sms/#intro","title":"Intro","text":"<p>This is the service that we use to send SMS through our Africastalking SMS account. The service consists of an SMS SQS queue and an SMS lambda that listens on messages on the SMS queue then sends it through Africas talking.</p> <pre><code>sequenceDiagram\n  autonumber\n  SQS Queue-&gt;&gt;SQS Lambda: Read SMS\n  SQS Lambda--&gt;&gt;Africas Talking: Send SMS\n  Africas Talking--&gt;&gt;SQS Lambda: Send SMS Response</code></pre>"},{"location":"sms/#sms-sqs-queue","title":"SMS SQS Queue","text":"<p>The SMS SQS queue is an AWS SQS queue named <code>africastalking-queue</code> deployed in aws region <code>me-south-1</code>. The queue definition was done via terraform and files are found in /terraform/sqs/sms/*</p> <p>Note</p> <p>To update the queue or it's properties update the queue's terraform files with the properties you want and apply the terrafom changes using <code>terraform apply</code></p>"},{"location":"sms/#sms-lambda","title":"SMS lambda","text":"<p>The SMS Lambda is an AWS lambda function named <code>sms_astalking</code> deployed in AWS region <code>me-south-1</code>. The lambda function definition is done in terraform and the files are found in /terraform/sms/lambda/*. The functions dependencies are bundled into lambda layers which the function uses. The lambda layer terraform definition is found in /terraform/sms/layers/*. The function source code is written in python3 and it is found in /sms/*</p> <p>Note</p> <p>To update the function raise a PR with your changes on either terraform or the source code, when you merge the code the changes will be auto deployed.</p>"},{"location":"sms/#secrets","title":"Secrets","text":"<p>The SMS Lambda function has 2 secrest configured <code>AFRICASTALKING_USERNAME</code> and <code>AFRICASTALKING_API_KEY</code>. The <code>AFRICASTALKING_USERNAME</code> is found on our africastalking dashboard bellow the app name as Username</p> <p></p> <p>The <code>AFRICASTALKING_API_KEY</code> is generated by cliking settings on the africastalking dashboad then API key. You will be propted to eneter your password to generate the key.</p> <p>Danger</p> <p>if you generate a new API key the one configured in production will stop being valid and SMSs being sent will fail. You will need to update this production secret with the one you generated then do a re-deploy of the SMS lambda function</p> <p>The two secrets are stored on our side using AWS Secrets manager the secret key is called <code>africastalking-prod-secrets</code>. To update these values log into the AWS console and go to  Secrets Manager. From the list of secrets, choose <code>africastalking-prod-secrets</code>. On the secret details page, on the Overview tab, in the Secret value section, choose Retrieve secret value and then choose Edit, the update the secrets.</p>"},{"location":"xussd/","title":"USSD Service","text":""},{"location":"xussd/#intro","title":"Intro","text":"<p>This is the service that we use to handle USSD redirection webhooks from Africastalking when a user dials our USSD code <code>*7*8*9*6#</code>. The service consists of a USSD lambda (exposes a lambda URL which we configure on our USSD shortcode on the Africastlaking dashboad as our USSD code's callback URL), and a dynamo DB to store USSD sessions and user inputs.</p> <pre><code>flowchart TD\nA[/Africa's talking\\]\nF[/USSD Lambda Function\\]\nD[(Dynamo DB)]\nC[\\Core service internal API/]\n\nA --&gt; F\nF --&gt; D\nF --&gt; C\n</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  User Phone-&gt;&gt;Telco: User dials USSD short code\n  Telco-&gt;&gt;Africas Talking: Send webhook\n  Africas Talking-&gt;&gt;USSD Lambda: Send webhook\n  USSD Lambda--&gt;&gt;Dynamo DB: Get/Create USSD Session\n  Dynamo DB--&gt;&gt;USSD Lambda: Get/Create USSD Session Response\n  USSD Lambda--&gt;&gt;Core service internal API: Get Data\n  USSD Lambda--&gt;&gt;Dynamo DB: Store data on USSD Session\n  USSD Lambda-&gt;&gt;Africas Talking: Webhook response\n  Africas Talking-&gt;&gt;Telco: Webhook Response\n  Telco-&gt;&gt;User Phone: Render USSD menu</code></pre>"},{"location":"xussd/#ussd-lambda","title":"USSD lambda","text":"<p>The USSD Lambda is an AWS lambda function named <code>ussd-lambda</code> deployed in AWS region <code>me-south-1</code>. The lambda function definition is done in terraform and the files are found in /terraform/ussd/lambda/*. The functions dependencies are bundled into lambda layers which the function uses. The lambda layer terraform definition is found in /terraform/ussd/layers/*. The function source code is written in Javascript and it is found in /ussd/*</p> <p>Note</p> <p>To update the function raise a PR with your changes on either terraform or the source code, when you merge the code the changes will be auto deployed.</p>"},{"location":"xussd/#dynamo-db","title":"Dynamo DB","text":"<p>The USSD Dynamodb is an AWS Amazon DynamoDB table named <code>ussd-sessions</code> deployed in aws region <code>me-south-1</code>. The Dynamodb definition was done via terraform and files are found in /terraform/data_stores/dynamodb/*</p> <p>Note</p> <p>To update the Dynamodb table or it's properties update the queue's terraform files with the properties you want and apply the terrafom changes using <code>terraform apply</code></p>"},{"location":"xussd/#africastalking-ussd-code-callback-configuration","title":"Africastalking USSD Code callback configuration","text":"<p>Danger</p> <p>Updating the callback URL will casue your USSD service to have downtime if you configure it to an invalid URL(URL that is not the USSSD lambda URL) We suggest that you backup the existing value so that you can rollback if you make a mistake.</p> <ul> <li>On the Africastalking dashboad click USSD then select Service Codes. </li> </ul> <p></p> <ul> <li>On the list of the service Codes that apper click the  humbager on the srervice code that you want to update and select callback.</li> </ul> <p></p> <ul> <li>On pop up menu that appers update the callback URL with the new URL or your lambda if you are changeing the service to pint to a new lambda or USSD service.</li> </ul> <p> -  click save to save and exit.</p>"},{"location":"zcore/","title":"Core Service","text":""},{"location":"zcore/#intro","title":"Intro","text":"<p>The core service is a serise of micro services built in python/Flask and connected to our main postgres database. It Exposes all APIs needed to perform any manupulation of the digital wallet. It has two types of APIs it exposes 1. internal API (Used by the ussd service to manupilate and query the wallet) 2. External API (Used by the demo webapp to manipulate and query the wallet). The core services consists of 3 types of layers; API layer, Webhook layer and worker layer which are deployed as separate micro services in docker containers on AWS ECS.</p> <pre><code>flowchart TD\nE[/External API\\]\nI[/internal API\\]\nW[/webhooks\\]\nZ[/event workers\\]\nQ&gt;Event queue]\nD[(Primary database)]\nK[\\Demo webapp/]\nJ[\\USSD service/]\n\nJ --&gt; I\nK --&gt; E\nI --&gt; D\nK --&gt; D\nW --&gt; D\nQ --&gt; Z\nZ --&gt; D\n\n\n</code></pre>"},{"location":"zcore/#load-balancers","title":"Load Balancers","text":"<p>We use Application loadbalancers (ALBs) to balanace the tarffic going to our Apps running on ECS services (containers), the ECS services are atached to the ALBs via target groups. We have two types of loadbalances that we expose to all our services:</p> <ol> <li> <p>Internal Load balancer - This load balancer is named <code>backend</code> and is deployed on our internal subnet of our VPC (This subnet is not accesible over the public internet). In this Load balancer we attach API services that we don not want things to reach directly from the internet. Services attached here currently are</p> <ul> <li>Internal API/ USSD API</li> <li>Extrenal API/ WEB API</li> </ul> <p>Info</p> <p>If you use the terraform module ecs_service to create your service it will be attached to the internal ALB by default unless you specify otherwise.</p> </li> <li> <p>External Load balancer - This load  balancer is named <code>backend-external</code> and is deployed in our External subnets of our VPC(This subnet is accesible over the public internet). In this Load balancer we attach API services that we  want things to reach directly from the internet. Services attached here currently are:</p> <ul> <li>Webhooks</li> <li>Flask Admin</li> <li>Metabase</li> </ul> <p>Info</p> <p>If you use the terraform module ecs_service to create your service, you will need to specify <code>load_balancer_name    = \"backend-external\"</code> so that your service can be attached to this loadbalancer. </p> </li> </ol>"},{"location":"zcore/#internal-api-ussd-api","title":"Internal API/ USSD API","text":"<p>This is the API that is only exposed to internal api clients (Clients that are on our Production virtual private cloud) e.g the USSD service. This API is authenticated via basic authentication where the user name is the wallet owner phone number and the password  is the wallet owners wallet pin. This API primarily supports the USSD operation and it was designed to share as much data in one call to minimize the roundtrip in the USSD session.</p> <p>The internal API micro service is  an AWS ECS service named <code>core-api</code> deployed in AWS region <code>me-south-1</code>. The Ecs service definition is done in terraform and the files are found in /terraform/core_ecs_service/*. The flask blueprints for this micro service are found in /usrc/api/blueprints/*  excluding web folder</p>"},{"location":"zcore/#extending-internal-api-ussd-api","title":"Extending Internal API/ USSD API","text":"<p>To extedend the USSD API by ading a new endpoint can be done in 2 ways</p> <ol> <li>Adding an API endpoint on an existing falsk blueprint</li> <li>Adding an API endpoint by adding a new falsk bleuprint</li> </ol>"},{"location":"zcore/#adding-an-api-endpoint-on-an-existing-falsk-blueprint","title":"Adding An API Endpoint On An Existing Falsk Blueprint","text":"<p>Lets assume that we wanted to add a get /example_url endpoint on the beneficiary blueprint. We will need to:</p> <ol> <li> <p>Create the new flask view named ExampleView on the  beneficiary.py blueprints file.</p> <pre><code>class ExampleView(flask.views.MethodView):\n    def get():\n        return flask.Response()\n</code></pre> </li> <li> <p>Regiseter the <code>ExampleView</code> you've created above to the beneficiary blueprint by adding the following entries on the create_blueprint function inside the beneficiary.py blueprint file.</p> <pre><code>def create_blueprint(at_prefix, **kwargs):\n    blueprint = flask.Blueprint(\"Beneficiary\", __name__)\n    blueprint.api_url_for_cache = {}\n    blueprint.before_request(set_global_user)\n    blueprint.after_request(remove_global_user)\n    blueprint.register_error_handler(APIError, make_api_error)\n\n    def add_url_rule(rule, view_func):\n        blueprint.add_url_rule(rule, view_func=view_func)\n        key = \"Core_{}\".format(view_func.__name__)\n        if key in blueprint.api_url_for_cache:\n            raise ValueError(\"{} is already in the url_for_cache\".format(key))\n        blueprint.api_url_for_cache[key] = \"{}{}\".format(at_prefix, rule)\n\n    add_url_rule(\n        \"/beneficiary\",\n        view_func=BeneficiaryView.as_view(\"Beneficiary\"),\n    )\n    add_url_rule(\n        \"/supported_banks\",\n        view_func=BeneficiaryBankView.as_view(\"Banks\"),\n    )\n\n    add_url_rule(\n        \"/example_url\",\n        view_func=ExampleView.as_view(\"example\"),\n    )\n    return blueprint\n</code></pre> </li> <li> <p>create githiub pull request agains master, get a review and after being approved merge the changes to master.</p> </li> <li>When the changes are merged to master the CI/CD pipline kicks in and automatically deploys your changes. </li> <li>When the deploy is complete your new endpoint should be available to the ussd app via <code>GET http://internal-backend-892516406.me-south-1.elb.amazonaws.com/api/example_url</code></li> </ol>"},{"location":"zcore/#adding-an-api-endpoint-by-adding-a-new-falsk-bleuprint","title":"Adding an API endpoint by adding a new falsk bleuprint","text":"<p>Lets assume we want to add a new blueprint to the web API called example.py that conatians a flask view named ExampleView that returns a 200 response for an authenticated get request. We will need to:</p> <ol> <li> <p>Create the new example.py blueprint file in /src/api/blueprints/core/</p> </li> <li> <p>In the new blueprint we add the bew vie called ExampleView</p> <pre><code>import flask.views\n\n\nclass ExampleView(flask.views.MethodView):\n    def get():\n        return flask.Response()\n</code></pre> </li> <li> <p>Add the create_blueprint function and in it register the requred before and after request function hooks, error handler functions  and attach the view we have created.</p> <pre><code>import flask\nimport flask.views\nfrom api.blueprints.common import api_json_response, make_api_error, remove_global_user, set_global_user\nfrom api.blueprints.errors import APIError\n\n\nclass ExampleView(flask.views.MethodView):\n    def get():\n        return flask.Response()\n\n\ndef create_blueprint(at_prefix, **kwargs):\n    blueprint = flask.Blueprint(\"Example\", __name__)\n    blueprint.api_url_for_cache = {}\n    blueprint.before_request(set_global_user)\n    blueprint.after_request(remove_global_user)\n    blueprint.register_error_handler(APIError, make_api_error)\n\n    def add_url_rule(rule, view_func):\n        blueprint.add_url_rule(rule, view_func=view_func)\n        key = \"Core_{}\".format(view_func.__name__)\n        if key in blueprint.api_url_for_cache:\n            raise ValueError(\"{} is already in the url_for_cache\".format(key))\n        blueprint.api_url_for_cache[key] = \"{}{}\".format(at_prefix, rule)\n\n\n    add_url_rule(\n        \"/example_url\",\n        view_func=ExampleView.as_view(\"example\"),\n    )\n\n    return blueprint\n</code></pre> </li> <li> <p>On the /terraform/core_ecs_service/main.tf update the entry_point to start this new blueprint.</p> <pre><code>module \"core-service\" {\nsource                 = \"../modules/ecs_service\"\nservice_name          = \"core\"\nlaunch_name_prefix     = \"core-api\"\npath_pattern           = \"/api/*\"\nentry_point            = [\"api-run-server\", \"--workers\", \"2\", \"-i\", \"0.0.0.0\", \"-trace-id\", \"X-Amzn-Trace-Id\", \"core.example:/api\",  \"core.login_registartion:/api\", \"core.beneficiary:/api\", \"core.account:/api\", \"core.health:/api\"]\n}\n</code></pre> </li> <li> <p>create githiub pull request agains master, get a review and after being approved merge the changes to master.</p> </li> <li>When the changes are merged to master the CI/CD pipline kicks in and automatically deploys your changes. </li> <li>When the deploy is complete your new endpoint should be available to the ussd app via <code>GET http://internal-backend-892516406.me-south-1.elb.amazonaws.com/api/example_url</code></li> </ol>"},{"location":"zcore/#extrenal-api-web-api","title":"Extrenal API/ WEB API","text":"<p>This is the API that is exposed to external api clients (Clients that are anywhere on the internet) via the AWS API gateway e.g the Demo web APP. This API is authenticated via token based authentication where the bearer toke  is the cleark jwt token of an authenticated user on our cleark account.</p> <p>The External API micro service is  an AWS ECS service named <code>web-core</code> deployed in AWS region <code>me-south-1</code>. The Ecs service definition is done in terraform and the files are found in /terraform/web_core_ecs_service/*. The flask blueprints for this micro service are found in /usrc/api/blueprints/web/* </p> <p>The web API blueprints uses the <code>set_clerk_global_user</code> function to check authentication and pull a user from a cleark id conatained on the cleark JWT tokn.</p> <p>If you are creating an Example Blueprint and you want to add cleark authentication, register the set_clerk_global_user function as a before request handler as shown bellow.</p> <pre><code>...\nimport flask.views\nfrom api.blueprints.common import api_json_response, make_api_error, remove_global_user, set_clerk_global_user\nfrom api.blueprints.errors import APIError\n...\n\nclass ExampleView(flask.views.MethodView):\n    def get():\n        ...\n\ndef create_blueprint(at_prefix, **kwargs):\n    blueprint = flask.Blueprint(\"Example blueprint\", __name__)\n    blueprint.api_url_for_cache = {}\n    blueprint.before_request(set_clerk_global_user)\n    blueprint.after_request(remove_global_user)\n    blueprint.register_error_handler(APIError, make_api_error)\n\n    def add_url_rule(rule, view_func):\n        blueprint.add_url_rule(rule, view_func=view_func)\n        key = \"Core_{}\".format(view_func.__name__)\n        if key in blueprint.api_url_for_cache:\n            raise ValueError(\"{} is already in the url_for_cache\".format(key))\n        blueprint.api_url_for_cache[key] = \"{}{}\".format(at_prefix, rule)\n\n\n    add_url_rule(\n        \"/example_url\",\n        view_func=ExampleView.as_view(\"example\"),\n    )\n\n    return blueprint\n</code></pre> <p>The API gateway is named backend-apigw is defined interraform in /terraform/api_gateway/* the definition consits of:</p> <ul> <li>The API gateway DNS api.exodusmobility.io</li> <li>The API gateway integration which is a v2 integration that is a HTTP_PROXY integration to the internal Aplication Load balancer via the API gateway VPC link.</li> <li>The API gateway route to route any traffic hitting it at <code>/api/*</code> to be fowarded to the internal ALB via the above gateway integration.</li> </ul>"},{"location":"zcore/#extending-extrenal-api-web-api","title":"Extending Extrenal API/ WEB API","text":"<p>To extedend the Web API by ading a new endpoint can be done in 2 ways</p> <ol> <li>Adding an API endpoint on an existing falsk blueprint</li> <li>Adding an API endpoint by adding a new falsk bleuprint</li> </ol>"},{"location":"zcore/#adding-an-api-endpoint-on-an-existing-falsk-blueprint_1","title":"Adding An API Endpoint On An Existing Falsk Blueprint","text":"<p>Lets assume that we wanted to add a get transaction by QID endpoint on the transactions blueprint. We will need to:</p> <ol> <li> <p>Create the new flask view named TransactionView on the  transactions.py blueprints file.</p> <pre><code>class TransactionView(flask.views.MethodView):\n    def get(self, qid):\n        user = get_global_user()\n        try:\n            transaction = Receipt.from_qid(qid)\n        except ValueError:\n            CommonErrorCode.BAD_ARGUMENT_VALUE(reason=\"Invalid transaction_qid\")\n        return api_json_response(ReceiptSerializer(transaction), 200)\n</code></pre> </li> <li> <p>Regiseter the <code>TransactionView</code> you've created above to the transactions blueprint by adding the following entries on the create_blueprint function inside the transactions.py blueprint file.</p> <pre><code>def create_blueprint(at_prefix, **kwargs):\n    blueprint = flask.Blueprint(\"Transactions\", __name__)\n    blueprint.api_url_for_cache = {}\n    blueprint.before_request(set_clerk_global_user)\n    blueprint.after_request(remove_global_user)\n    blueprint.register_error_handler(APIError, make_api_error)\n\n    def add_url_rule(rule, view_func):\n        blueprint.add_url_rule(rule, view_func=view_func)\n        key = \"Core_{}\".format(view_func.__name__)\n        if key in blueprint.api_url_for_cache:\n            raise ValueError(\"{} is already in the url_for_cache\".format(key))\n        blueprint.api_url_for_cache[key] = \"{}{}\".format(at_prefix, rule)\n\n\n    add_url_rule(\n        \"/transactions\",\n        view_func=TransactionsView.as_view(\"transactions\"),\n    )\n\n    add_url_rule(\n        \"/transaction/&lt;qid&gt;\",\n        view_func=TransactionView.as_view(\"transaction\"),\n    )\n\n    return blueprint\n</code></pre> </li> <li> <p>create githiub pull request agains master, get a review and after being approved merge the changes to master.</p> </li> <li>When the changes are merged to master the CI/CD pipline kicks in and automatically deploys your changes. </li> <li>When the deploy is complete your new endpoint should be accesible via <code>GET https://api.exodusmobility.io/api/transaction/&lt;qid&gt;</code></li> </ol>"},{"location":"zcore/#adding-an-api-endpoint-by-adding-a-new-falsk-bleuprint_1","title":"Adding an API endpoint by adding a new falsk bleuprint","text":"<p>Lets assume we want to add a new blueprint to the web API called example.py that conatians a flask view named ExampleView that returns a 200 response for an authenticated get request. We will need to:</p> <ol> <li> <p>Create the new example.py blueprint file in /src/api/blueprints/core/web/</p> </li> <li> <p>In the new blueprint we add the bew vie called ExampleView</p> <pre><code>import flask.views\n\n\nclass ExampleView(flask.views.MethodView):\n    def get():\n        return flask.Response()\n</code></pre> </li> <li> <p>Add the create_blueprint function and in it register the requred before and after request function hooks, error handler functions  and attach the view we have created.</p> <pre><code>import flask\nimport flask.views\nfrom api.blueprints.common import api_json_response, make_api_error, remove_global_user, set_clerk_global_user\nfrom api.blueprints.errors import APIError\n\n\nclass ExampleView(flask.views.MethodView):\n    def get():\n        return flask.Response()\n\n\ndef create_blueprint(at_prefix, **kwargs):\n    blueprint = flask.Blueprint(\"Example\", __name__)\n    blueprint.api_url_for_cache = {}\n    blueprint.before_request(set_clerk_global_user)\n    blueprint.after_request(remove_global_user)\n    blueprint.register_error_handler(APIError, make_api_error)\n\n    def add_url_rule(rule, view_func):\n        blueprint.add_url_rule(rule, view_func=view_func)\n        key = \"Core_{}\".format(view_func.__name__)\n        if key in blueprint.api_url_for_cache:\n            raise ValueError(\"{} is already in the url_for_cache\".format(key))\n        blueprint.api_url_for_cache[key] = \"{}{}\".format(at_prefix, rule)\n\n\n    add_url_rule(\n        \"/example_url\",\n        view_func=ExampleView.as_view(\"example\"),\n    )\n\n    return blueprint\n</code></pre> </li> <li> <p>On the /terraform/web_core_ecs_service/main.tf update the entry_point to start this new blueprint.</p> <pre><code>module \"web-core-service\" {\nsource                 = \"../modules/ecs_service\"\nnumber_of_containers   = 1\nservice_name          = \"web\"\nalb_listener_port     = 443\nlaunch_name_prefix     = \"web-core\"\npath_pattern           = \"/api/*\"\nentry_point            = [\"api-run-server\", \"--workers\", \"2\", \"-i\", \"0.0.0.0\", \"-trace-id\", \"X-Amzn-Trace-Id\", \"core.web.example:/api\"  \"core.web.account:/api\", \"core.web.health:/api\", \"core.web.beneficiary:/api\", \"core.web.transactions:/api\"]\n}\n</code></pre> </li> <li> <p>create githiub pull request agains master, get a review and after being approved merge the changes to master.</p> </li> <li>When the changes are merged to master the CI/CD pipline kicks in and automatically deploys your changes. </li> <li>When the deploy is complete your new endpoint should be accesible via <code>GET https://api.exodusmobility.io/api/example_url</code></li> </ol>"},{"location":"zcore/#webhooks","title":"Webhooks","text":"<p>This is the micro service that handles webhook request from external platforms. Currently we recive webhooks from two platforms cleark and Tanda.</p> <ol> <li> <p>cleark - <code>SMS webhooks</code> -: OTP SMS to send to users phones via our SMS service           - <code>User Webhooks</code> -: webhooks sent due to a user change event on cleark (creation, user update, user delete). We use these events to sync with cleark user accounts.</p> </li> <li> <p>Tanda - <code>Tanda callbacks</code> :- callbacks that tanda sends back to us to update us on a transaction that we initiated via API          - <code>Tanda Notifications</code> :- Notifications send to us when a user makes a payment via the Tanda paybill or bank account to topup their wallet</p> </li> </ol> <p>This  micro service is  an AWS ECS service named <code>ipn</code> deployed in AWS region <code>me-south-1</code>. The Ecs service definition is done in terraform and the files are found in /terraform/ipn_ecs_service/*. The flask blueprints for this micro service are found in /usrc/api/blueprints/webhooks/* </p>"},{"location":"zcore/#configuring-cleark-webhooks","title":"Configuring cleark webhooks","text":"<ul> <li>To Add a new cleark webhook go to the Clerk Dashboard and navigate to the Webhooks page. Select the Add Endpoint button.</li> </ul> <ul> <li> <p>You'll be presented with a form where you can specify the URL of your backend endpoint. This is the URL where Clerk will send the webhook events. You can also specify the events you want to receive. For example, if you only want to receive events related to users, you can select the user option.</p> </li> <li> <p>Once you click the Create button, you'll be presented with your webhook endpoint dashboard. Here you can see the URL of your endpoint and the events you selected and you can also test your endpoint</p> </li> </ul>"},{"location":"zcore/#configuring-tanda-webhooks","title":"Configuring Tanda webhooks","text":"<p>Tanda webhooks are per virtual account and they are set at account creation. We usaually set the same endpoint which points to the webhook service. This config is added in code  for callbacks and confirmation endpoint </p> <p>To update this value Raise a pr and update those subsequent values then re-deploy all the services.</p> <p>Danger</p> <p>Do not update these values if you don't understand the consiquences of that action. Updating the values will only affect the newly created accounts and you will neeed to backfill the others via tanda API</p>"},{"location":"zcore/#event-worker","title":"Event Worker","text":"<p>This is the Micro service that listes to the events SQS queue and handle the event. Thi is  an AWS ECS service named <code>events-worker</code> deployed in AWS region <code>me-south-1</code>. The ECS service definition is done in terraform and the files are found in /terraform/event_worker_ecs_service/*. The source code for this worker is found in /usrc/api/workers/events_worker.py  The event types definitions and event handlers are found in /usrc/api/events/*</p> <p>Events can be triggerd from any micro service in the core service, this can be done by creating an event object form spcific event class and calling  <code>&lt;event object&gt;.emmit()</code> to trigger the event.</p> <p>For example to create a debit acccount event : <pre><code>event = DebitAccountEvent(\n    account=account, \n    amount=receipt.amount, \n    narration=\"some narration}\")\n    event.emmit_delayed(delay_seconds=10)\n</code></pre></p>"},{"location":"zcore/#event-types","title":"Event Types","text":"Event Type Description <code>REGISTER_ACCOUNT</code> register a wallet on exodus <code>ADJUST_ACCOUNT_BALANCE</code> update a wallets account balance <code>ACTIVATE_ACCOUNT_EVENT</code> sync a tanda wallet with the registerd exodus account <code>PAYMENT_STK_PUSH</code> send an stk push request to someoones phone <code>PAYMENT_DISBURSMENT</code> send  money from an exodus wallet to a valid chanel <code>PAYMENT_CHECK_STATUS</code> Check the satatus of a payment transacton on tandda <p>The event SQS queue is an AWS SQS queue named <code>events-queue</code> deployed in aws region <code>me-south-1</code>. The queue definition was done via terraform and files are found in /terraform/sqs/events/*</p> <p>Note</p> <p>To update the queue or it's properties update the queue's terraform files with the properties you want and apply the terrafom changes using <code>terraform apply</code></p>"},{"location":"zcore/#data-layer","title":"Data layer","text":"<p>We model the data layer of our core service around a postgres database. We use sqlalchemy as the ORM to interact with the said database. The databsae table models are found in /src/api/models/* of our code base.</p> <p>We use alembic to migrate our database. This is done automatically when you merge your data bse migrations to the main branch. The alembic configuration file is located here (alembic.ini) and the migration files are located in /src/api/models/alembic/versions/*</p> <p>All of our Alembic model classes must inherit from <code>model.BaseModel</code> class. This class is packed with utility methods and validators that are helpfull on the data layer. The new class will also be required to define a <code>__qid_prefix_</code> class variable and assign it a two letter workd to denote the QID that will be prefixed to the ID whil sharing the id via API. The QUD prefix selcted should not be already picked this value is unique.</p> <p>see example to addd a new table called some_new_table:</p> <p>Add the model class definition in models module</p> <pre><code>import sqlalchemy\n\nimport api.models as model\nsa = sqlalchemy\n\nclass SomeNewTable(model.BaseModel):\n    __tablename__ = \"some_new_table\"\n    __qid_prefix__ = \"SM\"\n\n    id = sa.Column(sa.Integer, primary_key=True)\n    created_when = sa.Column(sa.DateTime, nullable=False)\n    updated_when = sa.Column(sa.DateTime, onupdate=utcnow)\n    name = sa.Column(sa.Text, unique=True, nullable=False)\n</code></pre> <p>run alembic command in folder <code>/src/</code> to generate a migration file in <code>/src/api/models/alembic/versions/</code> folder.</p> <pre><code>alembic revision -m \"add new table some new table\"\n</code></pre> <p>On the generated migration template file, edit to add the actual migration on the <code>upgrade</code> and <code>downgrade</code> functions</p> <pre><code>\"\"\"Add new table some new table\n\nRevision ID: 79525dgdge\nRevises: 89999dbfdvfhf\nCreate Date: 2025-08-02 04:28:17.177534+00:00\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = \"79525dgdge\"\ndown_revision = \"89999dbfdvfhf\"\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\ndef upgrade():\n    op.create_table(\n        \"some_new_table\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"created_when\", sa.DateTime(), nullable=False),\n        sa.Column(\"updated_when\", sa.DateTime(), nullable=True),\n        sa.Column(\"name\", sa.String(), nullable=False),,\n        sa.PrimaryKeyConstraint(\"id\", name=op.f(\"pk_users_\")),,\n    )\n\n\ndef downgrade():\n    op.drop_table(\"some_new_table\")\n</code></pre> <p>Raise a PR and when you merge your PR to production your migrations will be run automatically by the continous deployemnet pipeline</p>"},{"location":"zcore/#monitoring","title":"Monitoring","text":"<p>We use Sentry for alertiing us when the softawer crashes in production due to any unforseen errors or bugs or updates that may have been made.  This notification will point you to the point on the code that is the culprit. For application logging This service uses papertrail to log. We use the papartrail dashboad to view the system logs on this microservice. use the two services to trobleshoot whenever you have issues with the system. </p>"},{"location":"zcore/#secrets","title":"Secrets","text":"<p>The core service has 5 secrest configured <code>DATABASE_URI</code>, <code>FLASK_SECRET_KEY</code>, <code>TANDA_BASE_URL</code>, <code>TANDA_CLIENT_ID</code>, <code>TANDA_CLIENT_SECRET</code>, and <code>TANDA_ORG_ID</code>. The 5 secrets are stored on our side using AWS Secrets manager the secret key is called <code>prod-secrets</code>. To update these values log into the AWS console and go to  Secrets Manager. From the list of secrets, choose <code>prod-secrets</code>. On the secret details page, on the Overview tab, in the Secret value section, choose Retrieve secret value and then choose Edit, the update the secrets.</p> <p>Danger</p> <p>only update any othe above secrest if you know the consiquences of what you are doing, you may corrupt data or lead to a system failure.</p>"},{"location":"zeaddmod/","title":"Adding A new Service","text":"<p>To add a new service to the mono-repo(dw-backend) </p> <ol> <li> <p>Add a new folder at the root of this repo with the name of your new service</p> </li> <li> <p>In the folder you created add your source files on the language you are developing i.e python, java, js etc</p> </li> <li> <p>Ensure you write test for your service and your test can be run by a test runner e.g nosetets/pytest if python etc</p> </li> <li> <p>Update the CI to include test for your new service by editing the git hub action CI file named ci.yml</p> <pre><code>....\n- name: Test &lt;The name of my service&gt;\n\n        run: |\n        pushd &lt;my new service folder name&gt;\n        &lt;commands to run the test of my service&gt;\n        popd\n</code></pre> </li> <li> <p>On <code>/terraform</code> folder add the terraform definitions of the infrastructure that your new service will be using i.e database definitions, lambda definitions etc basically any aws resource that you are adding for this new service. Name it to match the name of your service.</p> </li> <li> <p>Update the CD to include deployment of your new service by editing the git hub action  CD filr named deploy.aws.yml using the dorny/paths-filter@v2 add the file paths to your new service to be watched so that if any of them would change the CD will kick off your deploy step.</p> </li> <li> <p>Update the readME with the information about your new service such as how to run it, test it etc.</p> </li> </ol>"}]}